{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnkurMali/IST597_Spring_2022/blob/main/IST597_MLP_withkeras_collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v0hRDnJGY3bH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\wallace\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "C:\\Users\\wallace\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "C:\\Users\\wallace\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "C:\\Users\\wallace\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "C:\\Users\\wallace\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "C:\\Users\\wallace\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "C:\\Users\\wallace\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "C:\\Users\\wallace\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "C:\\Users\\wallace\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "C:\\Users\\wallace\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "C:\\Users\\wallace\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "C:\\Users\\wallace\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'tensorflow._api.v1.random' has no attribute 'set_seed'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4560/2719241393.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1234\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1234\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_dw_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accessing local variables before they are created.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dw_wrapped_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     if (self._dw_warning_count < _PER_MODULE_WARNING_LIMIT and\n\u001b[0;32m    108\u001b[0m         name not in self._dw_deprecated_printed):\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.random' has no attribute 'set_seed'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6dv_IcvjZJz6"
      },
      "outputs": [],
      "source": [
        "size_input = 32\n",
        "size_hidden = 128\n",
        "size_output = 1\n",
        "number_of_train_examples = 1000\n",
        "number_of_test_examples = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ANBNiazKZMxe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-0.7626090976959161"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train = np.random.randn(number_of_train_examples , size_input)\n",
        "y_train = np.random.randn(number_of_train_examples)\n",
        "X_test = np.random.randn(number_of_test_examples, size_input)\n",
        "y_test = np.random.randn(number_of_test_examples)\n",
        "y_train[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p29oB9imZQC0"
      },
      "outputs": [],
      "source": [
        "# Split dataset into batches\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DpGETHIzZj1T"
      },
      "outputs": [],
      "source": [
        "class MLP(tf.keras.Model):\n",
        "  def __init__(self, size_input, size_hidden, size_output, device=None):\n",
        "    super(MLP, self).__init__()\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden: int, size of hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "\n",
        "    # self.size_input = 32\n",
        "    # self.size_hidden = 128\n",
        "    # self.size_output = 1\n",
        "    # self.device = 'gpu'\n",
        "    self.size_input, self.size_hidden, self.size_output, self.device =\\\n",
        "    size_input, size_hidden, size_output, device\n",
        "    \n",
        "    # Initialize weights between input layer and hidden layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden]))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.random.normal([1, self.size_hidden]))\n",
        "     # Initialize weights between hidden layer and output layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden, self.size_output]))\n",
        "    # Initialize biases for output layer\n",
        "    self.b2 = tf.Variable(tf.random.normal([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.MLP_variables = [self.W1, self.W2, self.b1, self.b2]\n",
        "    \n",
        "  def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "  \n",
        "  def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    return tf.losses.mean_squared_error(y_true_tf, y_pred_tf)\n",
        "  \n",
        "  def backward(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)\n",
        "    with tf.GradientTape() as tape:\n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "      print(predicted)\n",
        "    grads = tape.gradient(current_loss, self.MLP_variables)\n",
        "    optimizer.apply_gradients(zip(grads, self.MLP_variables))\n",
        "        \n",
        "        \n",
        "  def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #Remember to normalize your dataset before moving forward\n",
        "    # Compute values in hidden layer\n",
        "    what = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    hhat = tf.nn.relu(what)\n",
        "    # Compute output\n",
        "    output = tf.matmul(hhat, self.W2) + self.b2\n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n",
        "    #Second add tf.Softmax(output) and then return this variable\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwg_5g_pZ56Z",
        "outputId": "8efb0a28-6177-4b95-9a2a-6fdfc0ce9700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Epoch = 1 - Average MSE:= 8568.365\n",
            "Number of Epoch = 2 - Average MSE:= 98.7626171875\n",
            "Number of Epoch = 3 - Average MSE:= 39.255\n",
            "Number of Epoch = 4 - Average MSE:= 24.67137890625\n",
            "Number of Epoch = 5 - Average MSE:= 18.821771484375\n",
            "Number of Epoch = 6 - Average MSE:= 13.8831875\n",
            "Number of Epoch = 7 - Average MSE:= 10.3695810546875\n",
            "Number of Epoch = 8 - Average MSE:= 9.0484462890625\n",
            "Number of Epoch = 9 - Average MSE:= 8.10452490234375\n",
            "Number of Epoch = 10 - Average MSE:= 6.61408740234375\n",
            "\n",
            "Total time taken (in seconds): 5.13\n"
          ]
        }
      ],
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10\n",
        "# Initialize model using GPU\n",
        "#mlp_on_gpu = MLP()\n",
        "mlp_on_gpu = MLP(size_input, size_hidden, size_output, device='cpu')\n",
        "time_start = time.time()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss_total_gpu = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(1234)).batch(20)\n",
        "  for inputs, outputs in train_ds:\n",
        "    preds = mlp_on_gpu.forward(inputs)\n",
        "    loss_total_gpu = loss_total_gpu + mlp_on_gpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
        "    mlp_on_gpu.backward(inputs, outputs)\n",
        "  print('Number of Epoch = {} - Average MSE:= {}'.format(epoch + 1, np.sum(loss_total_gpu) / X_train.shape[0]))\n",
        "time_taken = time.time() - time_start\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPpR1AmCRxMriefAOpBlarD",
      "include_colab_link": true,
      "name": "IST597_MLP_withkeras_collab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
